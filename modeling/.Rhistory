debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
View(out)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
View(out)
View(result)
View(Xstar)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
View(Xstar)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
View(result)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
View(result_2)
View(result)
View(result_2)
View(result)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
View(result)
View(result_2)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
c
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
rm(list=ls()) #house keeping
#load packages
packages <- c('plyr', 'jsonlite', 'DEoptim', "matrixcalc", "fields")
lapply(packages, require, character.only = TRUE)
# Input arguments for the script
args = commandArgs(TRUE)
#clusterid <- as.integer(args[1]) # set later at appropriate location
#homePath= args[2]
#input_file <- args[3]
#output_path <- args[4]
clusterid <- as.integer(1)
homePath <- '/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/'
input_file <- '/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/data_generation/modelResults/batch_exponential_2pars/simulatedData_4.csv'
output_path <- '/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/testFast/'
filename_input_list <- strsplit(input_file, split = "/")
filename_input <- filename_input_list[[1]][[length(filename_input_list[[1]])]]
############## DEBUG PARAMS ##################
##############################################
MAX_ITER_FITTING=2 # 200 is default
ROUNDS_CV=1 #Full fitting is 10
#Source dependencies
modelpath <-paste(homePath,'models.R',sep="")
source(modelpath)
nParticipants <- 100
##############################################################################################################
#Cluster configuration: (1 subject x model combination) per CPU
##############################################################################################################
#create list of all kernel functions
kernellist<-list(rbf)
kernelnames<-c("RBF")
#list of all acquisition functions
acqlist<-list(ucb)
acqnames<-c('UCB')
#create a matrix with combinations of subjectIds and model combinations
subjectComb <- expand.grid(1:nParticipants)
#sample random cluster id for testing
#clusterid <- sample(1:nrow(subjectComb),1)
subjectId <- clusterid #used to identify unique subjects
set.seed(clusterid) #set seed as the clusterid
##############################################################################################################
#Compile Experimental Data
##############################################################################################################
# import preprocessed data
data = read.csv(input_file)
#Normalize data to 0-1
data$z <- (data$z -50)/100 #normalized to [-.5,.5]
uid <- unique(data$id)[subjectId] #convert subjectId to uid
##############################################################################################################
#Model Fitting
##############################################################################################################
GRIDSIZE=10 #0-10 (11x11)
manhattan <- expand.grid('x1'=0:(GRIDSIZE), 'x2'=0:(GRIDSIZE))
#initialize Xtest
X_map<-as.matrix(expand.grid(0:GRIDSIZE,0:GRIDSIZE))
#Negative Log Likelihood of model prediction
#parameters are distinct for each individual model
#subjD = subset of data for a specific subject
#rounds to be considered
modelFit<-function(par, subjD, acquisition, k, rounds,returnPredictions=FALSE){
start_time <- Sys.time()
# Fixed GP parameters, sampled from distributions
lambda <- rlnorm(1,-.8,.5)
beta <- rlnorm(1,-.8,.5)
tau <- rexp(1,10)
parVec_gpr <- c(lambda, lambda, 1,rep(0.001,30))
# Parameters for error Variance function
recency <- par[1]
#proximinty <- par[2]
surprise <- par[2]
scaling <- if(length(par)==3) par[3] else NA
errVar_vec <- if(is.na(scaling)) c(recency,surprise) else c(recency,surprise,scaling)
#Vector to store negative log likelihods
nLL <- rep(0,length(rounds))
for (r in rounds){ #Begin looping through each round
#subset of data for round r
roundD <- subset(subjD, round==r)
horizon <- nrow(roundD)
#Observations of subject choice behavior
chosen <- roundD$chosen
chosen <- chosen[2:length(chosen)] # trim first observation, since it wasn't a choice but a randomly revealed tile
y  <- roundD$z[0:(horizon-1)] #trim off the last observation, because it was not used to inform a choice (round already over)
x1 <- roundD$x[0:(horizon-1)]
x2 <- roundD$y[0:(horizon-1)]
#create observation matrix
X<-as.matrix(cbind(x1,x2))
#make sure X is a matrix
X<-as.matrix(X)
Xnew<-as.matrix(X_map)
#Utilties of each choice
utilities <- NULL
prevPost <- NULL #set the previous posterior computation to NULL for the kalman filter
#loop through observations
for (i in 1:(horizon-1)){ #skip the last observation, because no choice was made based on that information
#new observation
X_t<-matrix(X[1:i,], ncol=2)
y1<-y[1:i]
#Which posterior function to use
if (inherits(k, "KalmanFilter")){# kalman filter model
out<- bayesianMeanTracker(x = X_t[i,], y=y[i], prevPost = prevPost, theta = parVec)
#update prevPost for the next round
prevPost <- out
}else if (inherits(k, 'GP_DEFAULT')){# Default GP
#paramList_gpr[[4]]<- gp_error_variance_linear(obs=data.frame(x1=X_t[,1],x2=X_t[,2],y=y1+.5),theta=errVar_vec)
#parVec_gpr <- replace(parVec_gpr, 4, gp_error_variance_linear(obs=data.frame(x1=X_t[,1],x2=X_t[,2],y=y1+.5),theta=errVar_vec))
out <- gpr(X.test=Xnew, theta=parVec_gpr, X=X_t, y=y1, k=k) #Mu and Sigma predictions for each of the arms
}else if (inherits(k, 'Null')){ #null model
out <- nullModel() #Mu and Sigma predictions for each of the arms; either GP or Kalman filter
}else if (inherits(k, 'GP')){ # GP with Heteroscedastic noise
#parVec_gpr <- replace(parVec_gpr, 4, gp_error_variance_linear(obs=data.frame(x1=X_t[,1],x2=X_t[,2],y=y1+.5),theta=errVar_vec_linear))
parVec_gpr <- replace(parVec_gpr, 4, gp_error_variance_exponential(obs=data.frame(x1=X_t[,1],x2=X_t[,2],y=y1+.5),theta=errVar_vec))
out <- gpr(X.test=Xnew, theta=parVec_gpr, X=X_t, y=y1, k=k) #Mu and Sigma predictions for each of the arms
}
#Slightly different function calls for each acquisition function
if (inherits(acquisition, "UCB")){ #UCB takes a beta parameter
utilityVec<-acquisition(out, c(beta))
} else if (inherits(acquisition, 'exploreCounts')){ #count-based exploration
utilityVec <- exploreCounts(out, roundD$chosen[1:i], c(beta))
}else{ #any other
utilityVec <- acquisition(out)
}
utilityVec <- utilityVec - max(utilityVec) #avoid overflow
utilities <- rbind(utilities, t(utilityVec)) # build horizon_length x options matrix, where each row holds the utilities of each choice at each decision time in the search horizon
}
#print(utilities)
#Softmax rule
p <- exp(utilities/tau)
p <- p/rowSums(p)
#avoid underflow by setting a floor and a ceiling
p <- (pmax(p, 0.00001))
p <- (pmin(p, 0.99999))
#Calculate Negative log likelihood
nLL[which(rounds==r)] <- -sum(log(p[cbind(c(1:(horizon-1)),chosen)]))
}
#end loop through rounds
#print(sum(nLL))
end_time <- Sys.time()
print(c("Multiple RBFs:",end_time-start_time))
if (returnPredictions==FALSE){ #Return only summed log loss for computing MLE
return(sum(nLL))  #Return negative log likelihoods of all observations
}else if (returnPredictions==TRUE){ #Return detailed dataframe of model predictions for outofsample predictions
detailedPredictions <- list(sum(nLL), p, roundD[2:20,'chosen']) #construct a list of summed log loss, model predictions, and chosen item
return(detailedPredictions) #return detailed predictions
}
}
##############################################################################################################
#Alternative modelfit implementation
#Used for testing time improvements
##############################################################################################################
modelFit_alt<-function(par, subjD, acquisition, k, rounds,returnPredictions=FALSE){
start_time <- Sys.time()
# Fixed GP parameters, sampled from distributions
lambda <- rlnorm(1,-.8,.5)
beta <- rlnorm(1,-.8,.5)
tau <- rexp(1,10)
parVec_gpr <- c(lambda, lambda, 1,rep(0.001,30))
# Parameters for error Variance function
recency <- par[1]
#proximinty <- par[2]
surprise <- par[2]
scaling <- if(length(par)==3) par[3] else NA
errVar_vec <- if(is.na(scaling)) c(recency,surprise) else c(recency,surprise,scaling)
#Vector to store negative log likelihods
nLL <- rep(0,length(rounds))
print((rounds))
nLL <- apply(rounds, 1, function(r){
#subset of data for round r
roundD <- subset(subjD, round==r)
horizon <- nrow(roundD)
#Observations of subject choice behavior
chosen <- roundD$chosen
chosen <- chosen[2:length(chosen)] # trim first observation, since it wasn't a choice but a randomly revealed tile
y  <- roundD$z[0:(horizon-1)] #trim off the last observation, because it was not used to inform a choice (round already over)
x1 <- roundD$x[0:(horizon-1)]
x2 <- roundD$y[0:(horizon-1)]
#create observation matrix
X<-as.matrix(cbind(x1,x2))
#make sure X is a matrix
X<-as.matrix(X)
Xnew<-as.matrix(X_map)
#Utilties of each choice
utilities <- NULL
prevPost <- NULL #set the previous posterior computation to NULL for the kalman filter
#loop through observations
####################### Inner loop also with apply #########################
####################### Inner loop also with apply #########################
####################### Inner loop also with apply #########################
horizon_vec <- c(1:(horizon-1))
utilities <- apply(horizon_vec, 1, function(i){
#new observation
X_t<-matrix(X[1:i,], ncol=2)
y1<-y[1:i]
#Which posterior function to use
if (inherits(k, "KalmanFilter")){# kalman filter model
out<- bayesianMeanTracker(x = X_t[i,], y=y[i], prevPost = prevPost, theta = parVec)
#update prevPost for the next round
prevPost <- out
}else if (inherits(k, 'GP_DEFAULT')){# Default GP
#paramList_gpr[[4]]<- gp_error_variance_linear(obs=data.frame(x1=X_t[,1],x2=X_t[,2],y=y1+.5),theta=errVar_vec)
#parVec_gpr <- replace(parVec_gpr, 4, gp_error_variance_linear(obs=data.frame(x1=X_t[,1],x2=X_t[,2],y=y1+.5),theta=errVar_vec))
out <- gpr(X.test=Xnew, theta=parVec_gpr, X=X_t, y=y1, k=k) #Mu and Sigma predictions for each of the arms
}else if (inherits(k, 'Null')){ #null model
out <- nullModel() #Mu and Sigma predictions for each of the arms; either GP or Kalman filter
}else if (inherits(k, 'GP')){ # GP with Heteroscedastic noise
#parVec_gpr <- replace(parVec_gpr, 4, gp_error_variance_linear(obs=data.frame(x1=X_t[,1],x2=X_t[,2],y=y1+.5),theta=errVar_vec_linear))
parVec_gpr <- replace(parVec_gpr, 4, gp_error_variance_exponential(obs=data.frame(x1=X_t[,1],x2=X_t[,2],y=y1+.5),theta=errVar_vec))
out <- gpr(X.test=Xnew, theta=parVec_gpr, X=X_t, y=y1, k=k) #Mu and Sigma predictions for each of the arms
}
#Slightly different function calls for each acquisition function
if (inherits(acquisition, "UCB")){ #UCB takes a beta parameter
utilityVec<-acquisition(out, c(beta))
} else if (inherits(acquisition, 'exploreCounts')){ #count-based exploration
utilityVec <- exploreCounts(out, roundD$chosen[1:i], c(beta))
}else{ #any other
utilityVec <- acquisition(out)
}
utilityVec <- utilityVec - max(utilityVec) #avoid overflow
utilities <- rbind(utilities, t(utilityVec)) # build horizon_length x options matrix, where each row holds the utilities of each choice at each decision time in the search horizon
return(utilities)
})
#print(utilities)
#Softmax rule
p <- exp(utilities/tau)
p <- p/rowSums(p)
#avoid underflow by setting a floor and a ceiling
p <- (pmax(p, 0.00001))
p <- (pmin(p, 0.99999))
#Calculate Negative log likelihood
nLL_round <- -sum(log(p[cbind(horizon_vec,chosen)]))
return(nLL_round)
})
end_time <- Sys.time()
print(c("Multiple RBFs:",end_time-start_time))
if (returnPredictions==FALSE){ #Return only summed log loss for computing MLE
return(sum(nLL))  #Return negative log likelihoods of all observations
}else if (returnPredictions==TRUE){ #Return detailed dataframe of model predictions for outofsample predictions
detailedPredictions <- list(sum(nLL), p, roundD[2:20,'chosen']) #construct a list of summed log loss, model predictions, and chosen item
return(detailedPredictions) #return detailed predictions
}
}
##############################################################################################################
#CROSS VALIDATION FUNCTION
##############################################################################################################
#function to plug in to the optimaztion routine
#leaveoutindex is [1,2,...,n_rounds]
cvfun<-function(selector, kernelFun, acquisition, leaveoutindex){
#subselect participant, horizon and rounds not left out
d1<-subset(data, id==selector)
#training set
rounds <- 1:ROUNDS_CV
trainingSet <- rounds[! rounds==leaveoutindex] #remove round specified by leaveoutindex
#test set
testSet <- leaveoutindex
#Set upper and lower bounds based on nParams
nParams_memory=2
# exponential with scaling param ? scaling=1, scaling=0
nParams_scaling=0
lbound <- c(rep(-3, nParams_memory),rep(0,nParams_scaling))
ubound <- c(rep(3, nParams_memory),rep(5,nParams_scaling))
#Begin cross validation routine
#TRAINING SET
fit<-DEoptim(modelFit_alt, lower=lbound, upper=ubound, subjD=d1, k=kernelFun, rounds = trainingSet, acquisition=acquisition, DEoptim.control(itermax=MAX_ITER_FITTING))
paramEstimates <- fit$optim$bestmem #MODEL DEPENDENT PARAMETER ESTIMATES
#TEST SET
predict <- modelFit_alt(par=paramEstimates, subjD=d1, acquisition=acquisition, k=kernelFun, rounds=testSet)
#output <- data.frame(loo=leaveoutindex, params=fit$optim$bestmem, nLL=predict[[1]],predictions=predict[[2]], chosen=predict[[3]]) # leaveoutindex, parameters, nLL,predictions, chosen....
output <- c(predict,fit$optim$bestmem) # leaveoutindex, parameters, nLL,predictions, chosen....
return(output) #return optimized value
}
##############################################################################################################
#OPTIMIZATION ROUTINE
##############################################################################################################
output <- c()
# Extend output with folder and name of input script
ifelse(!dir.exists(output_path), dir.create(output_path), "Folder exists already, all ok.")
output_path <- paste0(output_path,filename_input,"/")
ifelse(!dir.exists(output_path), dir.create(output_path), "Folder exists already, all ok.")
name<-paste0(output_path, subjectId)
start.time <- Sys.time()
roundList <- 1:ROUNDS_CV #Remove training round and bonus round
#cross-validation routine
for (r in roundList){ #loop through rounds in roundList
print(r)
cv <- cvfun(selector=uid, kernelFun=kernellist[[1]], acquisition = acqlist[[1]], leaveoutindex=r)
intermediate_name=paste0(name,"_round",r,".csv")
write.csv(cv,intermediate_name)
output <- rbind(output, cv)
}
#save the vector with kernel-acquisition-pair as name
final_name=paste0(name,".csv")
write.csv(output,final_name)
print(output)
end.time <- Sys.time()
elapsed <- end.time - start.time
print(elapsed)
##############################################################################################################
#THE END
##############################################################################################################
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
debugSource("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
source("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
source("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
source("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
source("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
source("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
source("/media/beel/DATA/___UNI___/Semester 4/Laborpraktikum/code/simulations/model-recovery/modelComparison_fast.R", echo=TRUE)
